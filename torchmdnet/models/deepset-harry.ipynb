{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-24T16:35:51.027701Z",
     "start_time": "2025-03-24T16:35:51.013010Z"
    }
   },
   "source": [
    "from typing import Callable, Dict, Optional, Union, List\n",
    "import typing\n",
    "import rich\n",
    "from rich import pretty\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric as tg\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import xavier_uniform_, zeros_\n",
    "from torch.nn import init, Dropout, BatchNorm1d\n",
    "\n",
    "from torch_geometric.nn import SAGEConv, GATConv\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "from torch_geometric import edge_index\n",
    "\n",
    "from torch_geometric.nn import global_add_pool, global_max_pool, global_mean_pool\n",
    "\n",
    "from torchmdnet.models.utils import (\n",
    "\tNeighborEmbedding,\n",
    "\tCosineCutoff,\n",
    "\tOptimizedDistance,\n",
    "\trbf_class_mapping,\n",
    "\tact_class_mapping,\n",
    "\tscatter,\n",
    ")\n",
    "\n",
    "__all__ = [\"DeepSet\"]\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T16:35:57.155756Z",
     "start_time": "2025-03-24T16:35:57.136958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DeepSet(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            base_cutoff: float,\n",
    "            outer_cutoff: float,\n",
    "            num_gates: int = 10,\n",
    "            k: int = 2,\n",
    "            max_num_neighbors: int = 400,\n",
    "            embedding_size: int = 256,\n",
    "            num_rbf=50,\n",
    "            expert_out_features: int = 128,\n",
    "            rbf_type: str = \"gauss\",\n",
    "            trainable_rbf: bool = False,\n",
    "            dtype: torch.dtype = torch.float32,\n",
    "            skip_duplicates: bool = False,\n",
    "    ):\n",
    "        super(DeepSet, self).__init__()\n",
    "\n",
    "        self.outer_cutoff = outer_cutoff\n",
    "        self.base_cutoff = base_cutoff\n",
    "        self.embedding_size = embedding_size\n",
    "        self.dtype = dtype\n",
    "        self.skip_duplicates = skip_duplicates\n",
    "        self.num_gates = num_gates\n",
    "\n",
    "        self.embedding = torch.nn.Linear(in_channels, hidden_channels)\n",
    "\n",
    "        self.sage1 = SAGEConv(2 * embedding_size, hidden_channels, aggr='mean')\n",
    "        self.sage2 = SAGEConv(hidden_channels, hidden_channels, aggr='sum')\n",
    "        self.sage3 = SAGEConv(hidden_channels, out_channels, aggr='max')\n",
    "\n",
    "        self.distance = OptimizedDistance(\n",
    "            base_cutoff,\n",
    "            outer_cutoff,\n",
    "            max_num_pairs=max_num_neighbors,\n",
    "            return_vecs=True,\n",
    "            loop=True,\n",
    "            box=None,\n",
    "            long_edge_index=True,\n",
    "            check_errors=True,\n",
    "        )\n",
    "\n",
    "        self.distance_expansion = rbf_class_mapping[rbf_type](\n",
    "            base_cutoff, outer_cutoff, num_rbf, trainable_rbf\n",
    "        )\n",
    "        self.distance_proj = nn.Linear(num_rbf, embedding_size, dtype=dtype)\n",
    "        self.cutoff = CosineCutoff(base_cutoff, outer_cutoff)\n",
    "        self.embedding = nn.Embedding(100, embedding_size, dtype=dtype)\n",
    "\n",
    "        self.neighbor_embedding = NeighborEmbedding(embedding_size, 20, base_cutoff, outer_cutoff, 100, dtype)\n",
    "        expanded_feature_dim = embedding_size + 3\n",
    "        self.d_ij_transform = nn.Linear(expanded_feature_dim, embedding_size, dtype=dtype)\n",
    "        self.a_i_transform = nn.Linear(embedding_size, embedding_size, dtype=dtype)\n",
    "        self.a_j_transform = nn.Linear(embedding_size, embedding_size, dtype=dtype)\n",
    "\n",
    "        self.gamma_transform = nn.Linear(3 * embedding_size, embedding_size, dtype=dtype)\n",
    "        self.W_g = nn.Parameter(torch.randn(embedding_size, num_gates) * 0.01)\n",
    "        self.W_noise = nn.Parameter(torch.randn(embedding_size, num_gates) * 0.01)\n",
    "        self.W_distance = nn.Parameter(torch.randn(embedding_size, num_gates) * 0.01)\n",
    "\n",
    "        self.t_parameters = nn.Parameter(torch.randn(num_gates) * 0.01)\n",
    "\n",
    "        self.experts = nn.ModuleList([\n",
    "            nn.Linear(embedding_size, expert_out_features, dtype=dtype)\n",
    "            for _ in range(num_gates)\n",
    "        ])\n",
    "        self.batch_norm1 = BatchNorm1d(hidden_channels)\n",
    "        self.batch_norm2 = BatchNorm1d(hidden_channels)\n",
    "        self.dropout = Dropout(p=0.1)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self,\n",
    "                z: torch.Tensor,\n",
    "                pos: torch.Tensor,\n",
    "                batch: torch.Tensor,\n",
    "                box: Optional[torch.Tensor] = None,\n",
    "                q: Optional[torch.Tensor] = None,\n",
    "                s: Optional[torch.Tensor] = None) -> typing.Tuple[\n",
    "            torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        x = self.embedding(z)\n",
    "\n",
    "        edge_index, edge_weight, edge_vec = self.distance(pos, batch, box)\n",
    "\n",
    "        edge_attr = self.distance_expansion(edge_weight)\n",
    "\n",
    "        mask = edge_index[0] != edge_index[1]\n",
    "        if not mask.all():\n",
    "            edge_index = edge_index[:, mask]\n",
    "            edge_weight = edge_weight[mask]\n",
    "            edge_attr = edge_attr[mask]\n",
    "            edge_vec = edge_vec[mask]\n",
    "\n",
    "        if self.skip_duplicates:\n",
    "            edge_index = edge_index[:, ::2]\n",
    "            edge_weight = edge_weight[::2]\n",
    "            edge_attr = edge_attr[::2]\n",
    "            edge_vec = edge_vec[::2]\n",
    "\n",
    "        edge_weight_cube = edge_weight ** 3\n",
    "        edge_weight_sqrt = torch.sqrt(edge_weight)\n",
    "\n",
    "        edge_vec = edge_vec / torch.norm(edge_vec, dim=1, keepdim=True)\n",
    "\n",
    "        C = self.cutoff(edge_weight)\n",
    "        d_ij_projection = self.distance_proj(edge_attr) * C.view(-1, 1)\n",
    "\n",
    "        edge_features = torch.cat(\n",
    "            [\n",
    "                d_ij_projection,\n",
    "                edge_weight_cube.view(-1, 1),\n",
    "                edge_weight_sqrt.view(-1, 1),\n",
    "                edge_weight.view(-1, 1)\n",
    "            ], dim=1\n",
    "        )\n",
    "\n",
    "        d_ij_t_projection = self.d_ij_transform(edge_features)\n",
    "        a_i_projection = self.a_i_transform(x[edge_index[0, :]])\n",
    "        a_j_projection = self.a_j_transform(x[edge_index[1, :]])\n",
    "\n",
    "        gamma_projection = self.gamma_transform(torch.concat(\n",
    "            [a_i_projection.squeeze(), a_j_projection.squeeze(), d_ij_t_projection], dim=1))\n",
    "\n",
    "        d_ij_expanded = torch.repeat_interleave(edge_weight, self.num_gates, dim=0)\n",
    "        d_ij_expanded = 1 / torch.clamp(\n",
    "            torch.abs(d_ij_expanded.view(\n",
    "                -1,\n",
    "                self.t_parameters.size(0)\n",
    "            ) - self.t_parameters),\n",
    "            min=1e-8\n",
    "        )\n",
    "        softmax_d_ij_expanded = F.softmax(d_ij_expanded, dim=1)\n",
    "\n",
    "        experts_output = [self.experts[i](gamma_projection) for i in range(self.num_gates)]\n",
    "\n",
    "        experts_contributions = [e_o * e_w for e_o, e_w in zip(experts_output, softmax_d_ij_expanded.split(1, dim=1))]\n",
    "        edge_level_output = torch.sum(torch.stack(experts_contributions, dim=0), dim=0)\n",
    "\n",
    "        atom_level_output_x = scatter(edge_level_output, edge_index[0], dim=0, reduce=\"sum\")\n",
    "\n",
    "        n_atoms = z.size(0)\n",
    "        atom_level_output = torch.zeros(n_atoms, self.experts[0].out_features, dtype=self.dtype, device=z.device)\n",
    "        vec = torch.zeros(n_atoms, 3, self.experts[0].out_features, dtype=self.dtype, device=z.device)\n",
    "\n",
    "        atom_level_output.index_add_(0, edge_index[0], edge_level_output)\n",
    "\n",
    "        edge_vec_expanded = edge_vec.unsqueeze(-1).repeat(1, 1, self.experts[\n",
    "            0].out_features)\n",
    "        weighted_edge_vec = edge_vec_expanded * edge_level_output.unsqueeze(1)\n",
    "        for dim in range(3):\n",
    "            weighted_edge_vec_dim = weighted_edge_vec[:, dim, :]\n",
    "            vec[:, dim, :].index_add_(0, edge_index[0], weighted_edge_vec_dim)\n",
    "\n",
    "        # @todo New code here GNN testng SAGE, concat edge features to pass all structural info into the model\n",
    "        aggregated_edge_features = scatter(edge_features, edge_index[0], dim=0, dim_size=x.size(0),reduce=\"mean\")\n",
    "        x = torch.cat([x, aggregated_edge_features], dim=1)\n",
    "\n",
    "        x = self.sage1(atom_level_output_x, edge_index)\n",
    "        x = F.silu(self.batch_norm1(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.sage2(x, edge_index)\n",
    "        x = F.silu(self.batch_norm2(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.sage3(x, edge_index)\n",
    "\n",
    "        # @todo pooling may or may not be useful i will run with and without.\n",
    "        out = global_mean_pool(x, batch)\n",
    "\n",
    "        return x, vec, z, pos, batch, out"
   ],
   "id": "7d4ee25a5eef899e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T12:23:31.169041Z",
     "start_time": "2025-03-19T12:23:31.166626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\tdef reset_parameters(self):\n",
    "\t\t... #Ngl i do not know what this does"
   ],
   "id": "74ce92ebcf36c1cb",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T12:23:31.490580Z",
     "start_time": "2025-03-19T12:23:31.482319Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 57,
   "source": [
    "def forward(self,\n",
    "            z: torch.Tensor,  # Type hints, here for readability and clarity\n",
    "            pos: torch.Tensor,\n",
    "            batch: torch.Tensor,\n",
    "            edge_index: torch.Tensor,\n",
    "            box: Optional[torch.Tensor] = None,\n",
    "            edge_attr: torch.Tensor = None,\n",
    "            q: Optional[torch.Tensor] = None,\n",
    "            s: Optional[torch.Tensor] = None) -> typing.Tuple[\n",
    "    torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:  # Model returns 5 tensors as input does not = output :)\n",
    "    \"\"\"\n",
    "    # Google style doc string\n",
    "    Args:\n",
    "        z:                                  # Size is like (n_atoms, 1)\n",
    "        pos:                                # Size is like (n_atoms, 3)\n",
    "        batch:                              # Size is like (n_atoms, 1)\n",
    "        box:                                # Size is like (3, 3)\n",
    "        q:                                  # Size is like (n_atoms, 1)\n",
    "        s:                                  # Size is like (n_atoms, 1)\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    x = self.node_embedding(z)\n",
    "    # Beginning the forward pass\n",
    "    # x = self.embedding(z) # Maps atomic numbers to learnable vectors, continuous representation\n",
    "\n",
    "    edge_index, edge_weight, edge_vec = self.distance(pos, batch, box)  # Finds pairs of atoms close and returns which atoms are connected, their distance and direction\n",
    "    if edge_attr is not None:\n",
    "        edge_attr = self.edge_embedding(edge_attr)\n",
    "\n",
    "    edge_weight: torch.Tensor  # Type hint, edge_weight is expected to be a tensor\n",
    "\n",
    "    # print(x_0)\n",
    "    edge_attr = self.distance_expansion(edge_weight)  # Converts raw distances between atoms into a better format, NN struggle with raw values\n",
    "\n",
    "    # edge_index = edge_index[:, edge_weight != 0]\n",
    "    # edge_weight = edge_weight[edge_weight != 0] # * Prevent self loops (No distance between same an atom so it should be 0)\n",
    "    # edge_vec = edge_vec[edge_vec != 0]\n",
    "    mask = edge_index[0] != edge_index[1]  # Mask used to handle anomalous data points, filters out self loops (source and target)\n",
    "    if not mask.all():  # Checks for any false values in the mask, if so then following code is executed\n",
    "        edge_index = edge_index[:, mask]\n",
    "        edge_weight = edge_weight[mask]\n",
    "        edge_attr = edge_attr[mask]\n",
    "        edge_vec = edge_vec[mask]  # Mask edge_vec as well\n",
    "\n",
    "    if self.skip_duplicates:  # this removes repeated edges in calculation (it means upper triangle matrix)\n",
    "        edge_index = edge_index[:, ::2]  # Slicing, selects every second edge so skips over dupes\n",
    "        edge_weight = edge_weight[::2]  # Slice with 2 to skip duplicate edges and keep only one direction\n",
    "        edge_attr = edge_attr[::2]\n",
    "        edge_vec = edge_vec[::2]\n",
    "\n",
    "    # Normalize edge_vec for masked edges (similar to TorchMD_ET)\n",
    "    edge_vec = edge_vec / torch.norm(edge_vec, dim=1, keepdim=True)\n",
    "\n",
    "    # Compute the cutoff and distance projection\n",
    "    C = self.cutoff(edge_weight)  # Applies cutoff function to edge weight tensor, limits interactions to certain threshold.\n",
    "    d_ij_projection = self.distance_proj(edge_attr) * C.view(-1, 1)  # Applies cutoff values to projections. If edge is zero then it is reflected here.\n",
    "\n",
    "    # Transform the distance projection, nuclear charges and atom embeddings\n",
    "    d_ij_t_projection = self.d_ij_transform(d_ij_projection)\n",
    "    a_i_projection = self.a_i_transform(x[edge_index[0, :]])  # Prepares for calculations\n",
    "    a_j_projection = self.a_j_transform(x[edge_index[1, :]])  # Enables message passing\n",
    "\n",
    "    gamma_projection = self.gamma_transform(torch.concat([a_i_projection.squeeze(), a_j_projection.squeeze(), d_ij_t_projection], dim=1))\n",
    "    # Combine the source and target atom features then apply transformation to better learn them\n",
    "\n",
    "    # Computing Z:\n",
    "    d_ij_expanded = torch.repeat_interleave(edge_weight, self.num_gates, dim=0)\n",
    "\n",
    "    d_ij_expanded = 1 / torch.clamp(\n",
    "        torch.abs(d_ij_expanded.view(\n",
    "            -1,\n",
    "            self.t_parameters.size(0)\n",
    "        ) - self.t_parameters),\n",
    "        min=1e-8  # Avoid division by zero\n",
    "    )\n",
    "    softmax_d_ij_expanded = F.softmax(d_ij_expanded, dim=1)\n",
    "\n",
    "    experts_output = [self.experts[i](gamma_projection) for i in range(self.num_gates)]\n",
    "\n",
    "    experts_contributions = [e_o * e_w for e_o, e_w in zip(experts_output, softmax_d_ij_expanded.split(1, dim=1))]\n",
    "    # do the sum of the experts_contributions\n",
    "    edge_level_output = torch.sum(torch.stack(experts_contributions, dim=0), dim=0)\n",
    "\n",
    "    # Doing aggregation over the atoms\n",
    "    atom_level_output_x = scatter(edge_level_output, edge_index[0], dim=0, reduce=\"sum\")\n",
    "\n",
    "    # Doing the equivariant operation\n",
    "    n_atoms = z.size(0)  # Number of atoms from z\n",
    "    atom_level_output = torch.zeros(n_atoms, self.experts[0].out_features, dtype=self.dtype, device=z.device)\n",
    "    vec = torch.zeros(n_atoms, 3, self.experts[0].out_features, dtype=self.dtype,\n",
    "                      device=z.device)  # Atom-level vector features\n",
    "\n",
    "    # Aggregate edge-level scalar output to atom-level using scatter_reduce (sum)\n",
    "    atom_level_output.index_add_(0, edge_index[0], edge_level_output)  # Sum edge outputs to source atoms\n",
    "\n",
    "    # Aggregate edge-level vector features to atom-level using scatter_reduce (sum)\n",
    "    # Map edge_vec (shape: (num_edges, 3)) to atom-level vec\n",
    "    # First, expand edge_vec to match expert_out_features\n",
    "    edge_vec_expanded = edge_vec.unsqueeze(-1).repeat(1, 1, self.experts[\n",
    "        0].out_features)  # Shape: (num_edges, 3, expert_out_features)\n",
    "    # Weight edge_vec_expanded by edge_level_output (broadcasting)\n",
    "    weighted_edge_vec = edge_vec_expanded * edge_level_output.unsqueeze(\n",
    "        1)  # Shape: (num_edges, 3, expert_out_features)\n",
    "    # Aggregate to atom-level using scatter_reduce (sum) for source atoms\n",
    "    for dim in range(3):  # Iterate over spatial dimensions (0, 1, 2)\n",
    "        # Extract the dim-th spatial component of weighted_edge_vec\n",
    "        weighted_edge_vec_dim = weighted_edge_vec[:, dim, :]  # Shape: (num_edges, expert_out_features)\n",
    "        # Aggregate to atom-level using index_add_ for source atoms\n",
    "        vec[:, dim, :].index_add_(0, edge_index[0], weighted_edge_vec_dim)\n",
    "\n",
    "    return atom_level_output_x, vec, z, pos, batch"
   ],
   "id": "ae69588b39844e16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T12:23:31.914064Z",
     "start_time": "2025-03-19T12:23:31.910201Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 58,
   "source": [
    "#\n",
    "\t\t# # Apply Noisy Top-K Gating to d_ij_t_projection\n",
    "\t\t# # Step 1: Compute H(x) with noise (Equation 4)\n",
    "\t\t# gating_scores = torch.matmul(d_ij_t_projection, self.W_g)  # x · W_g\n",
    "\t\t# noise_component = torch.randn_like(gating_scores) * F.softplus(\n",
    "\t\t# \ttorch.matmul(d_ij_t_projection, self.W_noise))  # StandardNormal() · Softplus(x · W_noise)\n",
    "\t\t# H_x = gating_scores + noise_component  # H(x)_i\n",
    "\t\t#\n",
    "\t\t# # Step 2: Apply KeepTopK (Equation 5)\n",
    "\t\t# # Keep only the top k values, set others to -inf\n",
    "\t\t# top_k_values, top_k_indices = torch.topk(H_x, self.k, dim=-1)  # Get top k values\n",
    "\t\t# mask_top_k = H_x >= top_k_values[..., -1:]  # Create mask for top k\n",
    "\t\t# H_x[~mask_top_k] = float('-inf')  # Set non-top-k values to -inf\n",
    "\t\t#\n",
    "\t\t# # Step 3: Apply Softmax (Equation 3)\n",
    "\t\t# gating_output = F.softmax(H_x, dim=-1)  # G(x) = Softmax(KeepTopK(H(x), k))\n",
    "\t\t#\n",
    "\t\t# # Replace softmax_gamma_projection with gating_output\n",
    "\t\t# # softmax_gamma_projection = gating_output\n",
    "\t\t#\n",
    "\t\t# # Vectorized expert routing using gamma_projection\n",
    "\t\t# # Ensure num_gates >= k to avoid out-of-bounds indices\n",
    "\t\t# if self.k > self.num_gates:\n",
    "\t\t# \traise ValueError(f\"k ({self.k}) cannot be greater than num_gates ({self.num_gates})\")\n",
    "\t\t#\n",
    "\t\t# # Expand gamma_projection to include k dimension (for top-k routing)\n",
    "\t\t# gamma_expanded = gamma_projection.unsqueeze(1).repeat(1, self.k, 1)  # Shape: (num_edges, k, embedding_size)\n",
    "\t\t#\n",
    "\t\t# # Adjust top_k_indices to be within bounds (0 to k-1) if needed, but ensure they map to valid gates\n",
    "\t\t# # Since top_k_indices comes from H_x (dim=num_gates), clip or validate indices\n",
    "\t\t# top_k_indices = top_k_indices.clamp(0, self.num_gates - 1)  # Ensure indices are within [0, num_gates-1]\n",
    "\t\t#\n",
    "\t\t# # Create expert indices for routing (map top_k_indices to expert indices, 0 to k-1 for simplicity)\n",
    "\t\t# expert_indices = top_k_indices % self.k  # Map to 0 to k-1 for expert selection (simplified routing)\n",
    "\t\t#\n",
    "\t\t# # Gather gamma_projection for each expert (broadcasting top-k indices)\n",
    "\t\t# # Use expert_indices to route to the k experts\n",
    "\t\t# expert_inputs = gamma_expanded.gather(1, expert_indices.unsqueeze(-1).expand(-1, -1, gamma_projection.size(\n",
    "\t\t# \t-1)))  # Shape: (num_edges, k, embedding_size)\n",
    "\t\t#\n",
    "\t\t# # Process through experts (vectorized)\n",
    "\t\t# # Stack expert outputs for all k experts\n",
    "\t\t# expert_outputs = torch.stack([self.experts[i](expert_inputs[:, i]) for i in range(self.k)], dim=1)\n",
    "\t\t# # Shape: (num_edges, k, expert_out_features)\n",
    "\t\t#\n",
    "\t\t# # Aggregate expert outputs using gating weights\n",
    "\t\t# gate_weights = gating_output.gather(1, top_k_indices)  # Shape: (num_edges, k)\n",
    "\t\t# gate_weights = gate_weights.unsqueeze(-1)  # Shape: (num_edges, k, 1)\n",
    "\t\t# edge_level_output = (expert_outputs * gate_weights).sum(dim=1)  # Shape: (num_edges, expert_out_features)\n",
    "\t\t#\n",
    "\t\t# # Aggregate edge-level output to atom-level using scatter_reduce\n",
    "\t\t# n_atoms = z.size(0)  # Number of atoms from z\n",
    "\t\t# atom_level_output = torch.zeros(n_atoms, self.experts[0].out_features, dtype=self.dtype, device=z.device)\n",
    "\t\t# vec = torch.zeros(n_atoms, 3, self.experts[0].out_features, dtype=self.dtype,\n",
    "\t\t#                   device=z.device)  # Atom-level vector features\n",
    "\t\t#\n",
    "\t\t# # Aggregate edge-level scalar output to atom-level using scatter_reduce (sum)\n",
    "\t\t# atom_level_output.index_add_(0, edge_index[0], edge_level_output)  # Sum edge outputs to source atoms\n",
    "\t\t#\n",
    "\t\t# # Aggregate edge-level vector features to atom-level using scatter_reduce (sum)\n",
    "\t\t# # Map edge_vec (shape: (num_edges, 3)) to atom-level vec\n",
    "\t\t# # First, expand edge_vec to match expert_out_features\n",
    "\t\t# edge_vec_expanded = edge_vec.unsqueeze(-1).repeat(1, 1, self.experts[\n",
    "\t\t# \t0].out_features)  # Shape: (num_edges, 3, expert_out_features)\n",
    "\t\t# # Weight edge_vec_expanded by edge_level_output (broadcasting)\n",
    "\t\t# weighted_edge_vec = edge_vec_expanded * edge_level_output.unsqueeze(\n",
    "\t\t# \t1)  # Shape: (num_edges, 3, expert_out_features)\n",
    "\t\t# # Aggregate to atom-level using scatter_reduce (sum) for source atoms\n",
    "\t\t# for dim in range(3):  # Iterate over spatial dimensions (0, 1, 2)\n",
    "\t\t# \t# Extract the dim-th spatial component of weighted_edge_vec\n",
    "\t\t# \tweighted_edge_vec_dim = weighted_edge_vec[:, dim, :]  # Shape: (num_edges, expert_out_features)\n",
    "\t\t# \t# Aggregate to atom-level using index_add_ for source atoms\n",
    "\t\t# \tvec[:, dim, :].index_add_(0, edge_index[0], weighted_edge_vec_dim)\n",
    "\t\t# # vec.index_add_(0, edge_index[0].unsqueeze(1).expand(-1, 3), weighted_edge_vec)\n",
    "\t\t#\n",
    "\t\t# # Optionally, normalize by the number of edges per atom if needed (e.g., for mean)\n",
    "\t\t# # edge_counts = torch.bincount(edge_index[0], minlength=n_atoms).float()\n",
    "\t\t# # edge_counts = edge_counts.clamp(min=1)  # Avoid division by zero\n",
    "\t\t# # atom_level_output = atom_level_output / edge_counts.unsqueeze(-1)\n",
    "\t\t# # vec = vec / edge_counts.unsqueeze(1).unsqueeze(-1)  # Normalize vec similarly\n",
    "\t\t#\n",
    "\t\t# # Replace softmax_gamma_projection with gating_output or atom-level output, depending on return\n",
    "\t\t# softmax_gamma_projection = gating_output  # Keep gating output for consistency (not used in return here)\n",
    "\t\t#\n",
    "\t\t# # Return tuple matching TorchMD_ET structure\n",
    "\t\t# return atom_level_output, vec, z, pos, batch\n",
    "\t\t#"
   ],
   "id": "51e9c1abd1bb4444"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T14:41:27.933386Z",
     "start_time": "2025-03-19T14:41:27.924054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "\timport torch\n",
    "\timport numpy as np\n",
    "\timport random\n",
    "\timport time\n",
    "\n",
    "\n",
    "\tdef set_seed(seed: int):\n",
    "\t\ttorch.manual_seed(seed)\n",
    "\t\tnp.random.seed(seed)\n",
    "\t\trandom.seed(seed)\n",
    "\t\tif torch.cuda.is_available():\n",
    "\t\t\ttorch.cuda.manual_seed(seed)\n",
    "\t\t\ttorch.cuda.manual_seed_all(seed)\n",
    "\t\ttorch.backends.cudnn.deterministic = True\n",
    "\t\ttorch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "\t# Define the forward method in DeepSet\n",
    "\tclass DeepSet(nn.Module):\n",
    "\t\tdef __init__(self, num_node_features, gcn_hidden_dim, num_atom_features, base_cutoff, outer_cutoff):\n",
    "\t\t\tsuper().__init__()\n",
    "\t\t\t# Add any necessary layer initializations here\n",
    "\t\t\tself.num_node_features = num_node_features\n",
    "\t\t\tself.gcn_hidden_dim = gcn_hidden_dim\n",
    "\t\t\tself.num_atom_features = num_atom_features\n",
    "\t\t\tself.base_cutoff = base_cutoff\n",
    "\t\t\tself.outer_cutoff = outer_cutoff\n",
    "\n",
    "\t\t\t# Example embeddings and layers:\n",
    "\t\t\tself.node_embedding = nn.Embedding(num_node_features, gcn_hidden_dim)\n",
    "\t\t\tself.edge_embedding = nn.Linear(3, gcn_hidden_dim)  # Corrected input to match the shape of `pos`\n",
    "\t\t\tself.experts = nn.ModuleList(\n",
    "\t\t\t\t[nn.Linear(gcn_hidden_dim, gcn_hidden_dim) for _ in range(10)]  # Assume 10 experts\n",
    "\t\t\t)\n",
    "\n",
    "\t\tdef forward(self, z, pos, batch):\n",
    "\t\t\t# Example forward pass using dummy functionality:\n",
    "\t\t\tz_embedding = self.node_embedding(z.squeeze(-1))\n",
    "\t\t\tpos_embedding = self.edge_embedding(pos)\n",
    "\n",
    "\t\t\t# Example operation with experts\n",
    "\t\t\toutputs = [expert(z_embedding) for expert in self.experts]\n",
    "\t\t\toutput = sum(outputs)  # Sum all expert outputs (replace with implementation logic)\n",
    "\n",
    "\t\t\t# Return example tensors\n",
    "\t\t\treturn output, pos_embedding, z, pos, batch\n",
    "\n",
    "\n",
    "\t# Set the seed\n",
    "\tset_seed(2000)\n",
    "\n",
    "\t# Initialize the model\n",
    "\tmodel = DeepSet(\n",
    "                   num_node_features=100,\n",
    "                   gcn_hidden_dim=64,\n",
    "                   num_atom_features=10,  # Added the missing argument\n",
    "                   base_cutoff=0.0,\n",
    "                   outer_cutoff=3.0,\n",
    "\t)\n",
    "\n",
    "\t# Generate random input\n",
    "\tz = torch.randint(0, 100, (18, 1))\n",
    "\tpos = torch.randint(0, 5, (18, 3), dtype=torch.float32)\n",
    "\tbatch = torch.zeros(18, dtype=torch.long)\n",
    "\n",
    "\t# Test the forward method of the model\n",
    "\tx, vec, z, pos, batch = model(z, pos, batch)"
   ],
   "id": "b80ce4b9264d53d5",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#10/04 New\n",
    "from typing import Callable, Dict, Optional, Union, List\n",
    "import typing\n",
    "import wandb\n",
    "import rich\n",
    "from networkx.classes.filters import hide_edges\n",
    "from rich import pretty\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as tg\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import relu_\n",
    "from torch.nn.init import xavier_uniform_, zeros_\n",
    "from torch.nn import init, Sequential, ReLU, SiLU\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, GATv2Conv, EdgeConv\n",
    "\n",
    "from torchmdnet.models.utils import (\n",
    "\tNeighborEmbedding,\n",
    "\tCosineCutoff,\n",
    "\tOptimizedDistance,\n",
    "\trbf_class_mapping,\n",
    "\tact_class_mapping,\n",
    "\tscatter,\n",
    ")\n",
    "\n",
    "# from src import utils\n",
    "# from src.properties import properties\n",
    "\n",
    "__all__ = [\"DeepSet\"]\n",
    "\n",
    "class DeepSet(nn.Module):\n",
    "\n",
    "\tdef __init__(\n",
    "\t\t\tself,\n",
    "\t\t\tin_channels: int = 128,\n",
    "\t\t\thidden_channels: int = 256,\n",
    "\t\t\tout_channels: int = 32,\n",
    "\t\t\tnum_gates: int = 10,\n",
    "\t\t\tskip_duplicates: bool = True,\n",
    "\t\t\tbase_cutoff: float = 0.0,\n",
    "\t\t\touter_cutoff: float = 5.0,\n",
    "\t\t\tk: int = 2,\n",
    "\t\t\tmax_num_neighbors: int = 400,\n",
    "\t\t\tembedding_size: int = 256,\n",
    "\t\t\tnum_rbf: int = 50,\n",
    "\t\t\texpert_out_features: int = 128,\n",
    "\t\t\trbf_type: str = \"gauss\",\n",
    "\t\t\ttrainable_rbf: bool = False,\n",
    "\t\t\tdtype: torch.dtype = torch.float32\n",
    "\t):\n",
    "\n",
    "\t\tsuper(DeepSet, self).__init__()\n",
    "\n",
    "\t\tself.outer_cutoff = outer_cutoff\n",
    "\t\tself.base_cutoff = base_cutoff\n",
    "\t\tself.embedding_size = embedding_size\n",
    "\t\tself.dtype = dtype\n",
    "\t\tself.skip_duplicates = skip_duplicates\n",
    "\t\tself.in_channels = in_channels\n",
    "\t\tself.hidden_channels = hidden_channels\n",
    "\t\tself.out_channels = out_channels\n",
    "\t\tself.num_gates = num_gates\n",
    "\n",
    "\t\t#Atom embedding\n",
    "\t\tself.atom_embedding = nn.Linear(1, 64)\n",
    "\t\t#self.projection_layer = nn.Linear(1152, 128)\n",
    "\t\t#self.projection_layer_x = nn.Linear(128, 256)\n",
    "\t\tself.gamma_transform = nn.Linear(256, 384) # ! Had to set to 384 to work with experts\n",
    "\t\t#self.gnn = nn.Sequential(SAGEConv(in_channels, hidden_channels), nn.SiLU(), SAGEConv(hidden_channels, hidden_channels))\n",
    "\n",
    "\t\tself.distance = OptimizedDistance(\n",
    "\t\t    base_cutoff,\n",
    "\t\t    outer_cutoff,\n",
    "\t\t    max_num_pairs=max_num_neighbors,\n",
    "\t\t    return_vecs=True,\n",
    "\t\t    loop=True,\n",
    "\t\t    box=None,\n",
    "\t\t    long_edge_index=True,\n",
    "\t\t    check_errors=True, # Set False if there are more than 10k neighbors and it throw an error. Check this thread: https://github.com/torchmd/torchmd-net/issues/203\n",
    "\t\t)\n",
    "\n",
    "\t\tself.distance_expansion = rbf_class_mapping[rbf_type](\n",
    "\t\t\tbase_cutoff, outer_cutoff, num_rbf, trainable_rbf\n",
    "\t\t)\n",
    "\t\t# Creates connected linear layer\n",
    "\t\tself.distance_proj = nn.Linear(32, 32, dtype=dtype) #transforms size num_rbf into embedding_size\n",
    "\t\tself.cutoff = CosineCutoff(base_cutoff, outer_cutoff) #Restrict interactions beyond a certain distance\n",
    "\t\tself.embedding = nn.Embedding(100, embedding_size, dtype=dtype) #Embedding layer maps ints\n",
    "\n",
    "\t\tself.neighbor_embedding = NeighborEmbedding(embedding_size, 20, base_cutoff, outer_cutoff, 100, dtype)\n",
    "\t\t#Part of a message passing NN/GNN\n",
    "\t\texpanded_feature_dim = embedding_size + 3\n",
    "\t\tself.d_ij_transform = nn.Linear(36, 128, dtype=dtype) #Refine how inter atomic distances contribute\n",
    "\t\tself.a_i_transform = nn.Linear(128, 128, dtype=dtype) #Project atom features into a common space before interactions\n",
    "\t\tself.a_j_transform = nn.Linear(128, 256, dtype=dtype) #When node i receives messages from j (neighbors) those messages are transformed properly.\n",
    "\n",
    "\t\t# ? New code 26/03\n",
    "\t\t#self.pairwise_transform = nn.Linear(embedding_size + 3, embedding_size, dtype=dtype)\n",
    "\n",
    "\t\t#self.edge = EdgeConv(128, 256)\n",
    "\t\t# self.norm1 = torch.nn.LayerNorm(256) Batch norm NOT for MD\n",
    "\t\t#self.gat1 = GATv2Conv(256, hidden_channels, aggr='mean')\n",
    "\t\t#nn_edge = Sequential(\n",
    "\t\t\t#nn.Linear(512, hidden_channels),\n",
    "\t\t\t#SiLU(),\n",
    "\t\t\t#nn.Linear(hidden_channels, hidden_channels)\n",
    "\t\t#)\n",
    "\n",
    "\t\t#self.edge1 = EdgeConv(nn_edge, aggr=' mean')\n",
    "\n",
    "\t\t#self.edge1 = GATConv(\n",
    "\t\t\t#in_channels=128,  # Correct clearly the input dimension as numeric (256 here explicitly given)\n",
    "\t\t\t#out_channels=hidden_channels,  # Correct clearly specifying numeric output dimensions\n",
    "\t\t\t#heads=4,  # Recommended explicitly: clearly defined head number\n",
    "\t\t\t#concat=True,  # Recommended explicitly: typically True for GAT\n",
    "\t\t\t#dropout=0.1  # Optional explicitly: often helpful in practice\n",
    "\t\t#)\n",
    "\n",
    "\t\t#self.sage2 = tg.nn.SAGEConv(256, 256, aggr='mean6')\n",
    "\n",
    "\t\t# self.sage3 = tg.nn.SAGEConv(256, 256, aggr='max')\n",
    "\n",
    "\t\t# self.lin = torch.nn.Linear(hidden_channels, out_channels, dtype=dtype)\n",
    "\t\t# self.lin = torch.nn.Linear(256, 64)\n",
    "\n",
    "\t\tself.concat_projection = nn.Linear(5 * hidden_channels, 256)\n",
    "\n",
    "\t\t#nn.init.xavier_uniform_(self.embedding.weight)\n",
    "\n",
    "\t\t#Gated message passing system\n",
    "\t\tself.gamma_transform = nn.Linear(512, 256, dtype=dtype) # 3 suggests processing diff inputs i.e. central, neighbour and edge\n",
    "\t\t# Shape: (num_features, num_gates)\n",
    "\t\tself.W_g = nn.Parameter(torch.randn(embedding_size, num_gates) * 0.01)  # Small random initialization // gating mechanism controls info flow and selects important messages\n",
    "\n",
    "\t\t# Noise weight matrix W_noise\n",
    "\t\t# Shape: (num_features, num_gates)\n",
    "\t\tself.W_noise = nn.Parameter(torch.randn(embedding_size, num_gates) * 0.01)  # Small random initialization\n",
    "\n",
    "\t\t# Distance Learnable Parameters (Steven's method)\n",
    "\t\tself.W_distance = nn.Parameter(torch.randn(embedding_size, num_gates) * 0.01)\n",
    "\n",
    "\t\tself.t_parameters = nn.Parameter(torch.randn(num_gates) * 0.01)\n",
    "\n",
    "\t\t# Hyperparameter k for top-k selection\n",
    "\t\t# self.k = k\n",
    "\t\tself.num_gates = num_gates\n",
    "\n",
    "\t\tself.experts = nn.ModuleList([ #List of independent layers with each acting as an expert\n",
    "\t\t\tnn.Linear(256, 128, dtype=dtype)\n",
    "\t\t\tfor _ in range(num_gates)  # One expert per gate (to handle all possible gates)\n",
    "\t\t])\n",
    "\t\t#Gating mechanism chooses which experts contribute to output.\n",
    "\n",
    "\tdef reset_parameters(self):\n",
    "\t\t...\n",
    "\n",
    "\t#Numpy style docstring\n",
    "\tdef forward(self,\n",
    "\t            z: torch.Tensor, # Type hints, here for readability and clarity\n",
    "\t            pos: torch.Tensor,\n",
    "\t            batch: torch.Tensor, #based on batch can say how many indexes belong to one molecule, print nd compare with z + pos\n",
    "\t            box: Optional[torch.Tensor] = None,\n",
    "\t            q: Optional[torch.Tensor] = None,\n",
    "\t            s: Optional[torch.Tensor] = None) -> typing.Tuple[\n",
    "\t\ttorch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "\t\t\"\"\"\n",
    "\t\t#Google style doc string\n",
    "\t\tArgs:\n",
    "\t\t\tz:                                  # Size is like (n_atoms, 1)\n",
    "\t\t\tpos:                                # Size is like (n_atoms, 3)\n",
    "\t\t\tbatch:  \t\t\t\t\t\t    # Size is like (n_atoms, 1)\n",
    "\t\t\tbox:            \t\t            # Size is like (3, 3)\n",
    "\t\t\tq:                                  # Size is like (n_atoms, 1)\n",
    "\t\t\ts:      \t\t\t\t\t        # Size is like (n_atoms, 1)\n",
    "\n",
    "\t\tReturns:\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\t#Beginning the forward pass, ! had to squeeze to fix dimension errors\n",
    "\t\t#z = z.view(-1, 1)\n",
    "\t\tx = self.embedding(z)\n",
    "\t\t#x = nn.Dropout(0.1)(x)\n",
    "\t\t#print(\"z shape before SAGEConv:\", z.shape)\n",
    "\t\t#print(f\"x shape before SAGEConv: {x.shape}\") # should be numnodes, 64\n",
    "\n",
    "\n",
    "\t\tedge_index, edge_weight, edge_vec = self.distance(pos, batch, box) #Finds pairs of atoms close and returns which atoms are connected, their distance and direction\n",
    "\t\t#Edge weight distance, take as x\n",
    "\n",
    "\t\t#num_nodes = z.shape[0]\n",
    "\t\t#if edge_index.max() >= num_nodes:\n",
    "\t\t\t#print(f'Edge index contains out of bounds value')\n",
    "\t\t\t#edge_index = edge_index.clamp(0, num_nodes - 1)\n",
    "\n",
    "\t\t#edge_index = edge_index.long()\n",
    "\n",
    "\t\tedge_attr = self.distance_expansion(edge_weight) #Converts raw distances between atoms into a better format, NN struggle with raw values\n",
    "\t\t# ! New code 26/03\n",
    "\t\t#edge_proj = self.distance_proj(edge_attr)\n",
    "\t\t#edge_vec = edge_vec / (torch.norm(edge_vec, dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "\t\t#print(\"edge_weight shape (mask):\", (edge_weight != 0).shape) # 142\n",
    "\t\t#print(\"edge_attr shape:\", edge_attr.shape) # 142, 50\n",
    "\n",
    "\t\t#edge_index = edge_index[:, edge_weight != 0]\n",
    "\t\t#edge_weight = edge_weight[edge_weight != 0] # * Prevent self loops (No distance between same an atom so it should be 0)\n",
    "\t\t#edge_vec = edge_vec[edge_vec != 0]\n",
    "\n",
    "\t\t#print(\"After filtering zeros:\")\n",
    "\t\t#print(\"edge_weight.shape:\", edge_weight.shape)\n",
    "\t\t#print(\"edge_attr.shape:\", edge_attr.shape)\n",
    "\n",
    "\t\tmask = edge_index[0] != edge_index[1] #Mask used to handle anomalous data points , filters out self loops (source and target)\n",
    "\t\tif not mask.all(): #Checks for any false values in the mask, if so then following code is executed\n",
    "\t\t\tedge_index = edge_index[:, mask]\n",
    "\t\t\tedge_weight = edge_weight[mask]\n",
    "\t\t\tedge_attr = edge_attr[mask]\n",
    "\t\t\tedge_vec = edge_vec[mask]\n",
    "\t\t\t#edge_proj = edge_proj[mask]# Mask edge_vec as well\n",
    "\n",
    "\t\t#print(f\"Mask shape:\", mask.shape)\n",
    "\n",
    "\t\tif self.skip_duplicates: # this remove repeated edges in calculation (it means upper triangle matrix)\n",
    "\t\t\tedge_index = edge_index[:, ::2] #Slicing, selects every second edge so skips over dupes\n",
    "\t\t\tedge_weight = edge_weight[::2] #Slice with 2 to skip duplicate edges and keep only one direction\n",
    "\t\t\tedge_attr = edge_attr[::2]\n",
    "\t\t\tedge_vec = edge_vec[::2]\n",
    "\t\t\t#edge_proj = edge_proj[::2]\n",
    "\n",
    "\t\t#edge_index = edge_index.float()\n",
    "\n",
    "\t\t#print(f\"Edge index shape: {edge_index.shape}\") # [2, 62]\n",
    "\t\t#print(f\"Max index in edge_index: {edge_index.max().item()}\") # 17 , none out of bounds\n",
    "\t\t#print(f\"Number of nodes (atoms): {z.shape[0]}\")  # 18\n",
    "\n",
    "\t\t#print(f\"Edge weight sample: {edge_weight[:5]}\")\n",
    "\t\t#print(f\"Edge vec sample: {edge_vec[:5]}\") Aligned properly\n",
    "\n",
    "\t\t#print(f\"Min edge index: {edge_index.min().item()}\") # 1\n",
    "\t\t#print(f\"Max edge index: {edge_index.max().item()}\") # 17\n",
    "\n",
    "\t\t#print(f\"Node feature shape: {x.shape}\")  # ([18, 1, 256)]) but needs to be 2D so is causing an issue\n",
    "\n",
    "\t\t# Added for project\n",
    "\t\tedge_weight_sq = edge_weight ** 2\n",
    "\t\tedge_weight_cube = edge_weight ** 3\n",
    "\t\t#edge_weight_tet = edge_weight ** 4\n",
    "\t\tedge_weight_sqrt = torch.sqrt(edge_weight)\n",
    "\t\t#edge_weight_log = torch.log(edge_weight)\n",
    "\n",
    "\t\tedge_weight: torch.Tensor  # Type hint, edge_weight is expected to be a tensor\n",
    "\n",
    "\t\t# Normalize edge_vec for masked edges (similar to TorchMD_ET)\n",
    "\t\tedge_vec = edge_vec / torch.norm(edge_vec, dim=1, keepdim=True)\n",
    "\t\t#edge_vec.squeeze(3)\n",
    "\n",
    "\t\t#? New code for RBF here 02/04\n",
    "\t\t#edge_attr_dist = self.distance_expansion(edge_weight)\n",
    "\t\t#edge_attr_cub = self.distance_expansion(edge_weight_cube)\n",
    "\t\t#edge_attr_sqrt = self.distance_expansion(edge_weight_sqrt)\n",
    "\n",
    "\t\t#edge_attr = torch.cat([edge_attr_dist, edge_attr_cub, edge_attr_sqrt], dim=1)\n",
    "\n",
    "\t\t#print(f\"Edge weight shape: {edge_weight.shape}\")\n",
    "\t\t#print(f\"Edge vec shape: {edge_vec.shape}\")\n",
    "\n",
    "\t\t# Compute the cutoff and distance projection\n",
    "\t\tC = self.cutoff(edge_weight) # Applies cutoff function to edge weight tensor, limits interactions to certain threshold.\n",
    "\t\td_ij_projection = self.distance_proj(edge_attr) * C.view(-1, 1) # Applies cutoff values to projections. If edge is zero then it is reflected here.\n",
    "\n",
    "\t\t#print(f\"edge_proj shape: {edge_proj.shape}\") # 168, 256 clearly the issue\n",
    "\t\t#print(f\"edge_weight_cube shape: {edge_weight_cube.shape}\") # 75\n",
    "\t\t#print(f\"edge_weight_sqrt shape: {edge_weight_sqrt.shape}\") # 75\n",
    "\t\t#print(f\"edge_weight shape: {edge_weight.shape}\") # 75\n",
    "\t\t#print(f\"edge_vec shape: {edge_vec.shape}\") # 75,3 thus should flatten\n",
    "\n",
    "\t\t#edge_vec_flat = edge_vec.mean(dim=1)\n",
    "\n",
    "\n",
    "\t\t# !Concat new weights to the projection, since dim = 1 need to ensure concat along a column ??\n",
    "\t\tedge_features = torch.cat(\n",
    "[\n",
    "\t\t\td_ij_projection,\n",
    "\t\t\t edge_weight_sq.view(-1,1),\n",
    "\t\t\t edge_weight_cube.view(-1,1),\n",
    "\t\t\t #edge_weight_tet.view(-1,1),\n",
    "\t\t\t edge_weight_sqrt.view(-1,1),\n",
    "\t\t\t #edge_weight_log.view(-1,1),\n",
    "\t\t\t edge_weight.view(-1,1),\n",
    "\t\t\t#edge_vec_flat.view(-1,1)\n",
    "\t\t],\tdim=1\n",
    "\t\t)\n",
    "\n",
    "\t\t#print(f\"edge_proj shape : {edge_proj.shape}\")  #\n",
    "\t\t#print(f\"edge_weight_cube : {edge_weight_cube.shape}\")  # 75\n",
    "\t\t#print(f\"edge_weight_sqrt shape : {edge_weight_sqrt.shape}\")  # 75\n",
    "\t\t#print(f\"edge_weight shape : {edge_weight.shape}\")  # 75\n",
    "\t\t#print(f\"edge_vec shape : {edge_vec_flat.shape}\")\n",
    "\n",
    "\t\t# ? I have to transform 260 input to 259 output linearly, here accuracy will be lost\n",
    "\n",
    "\t\t#print(f\"x shape: {x.shape}\")  # [18, 256]\n",
    "\t\t#print(f'edge_features.shape BEFORE Linear: {edge_features.shape}')  # [77, 260]\n",
    "\t\t#assert edge_features.shape == (77, 260), f\"Unexpected shape: {edge_features.shape}\"\n",
    "\n",
    "\t\t#print(\"Edge features shape:\", edge_features.shape)  # (77, 260)\n",
    "\t\t#print(\"Expected input dim:\", self.d_ij_transform.in_features)  #  260\n",
    "\t\t#print(\"Expected output dim:\", self.d_ij_transform.out_features)  # 256\n",
    "\n",
    "\t\t#try:\n",
    "\t\t\t#d_ij_t_projection = self.d_ij_transform(edge_features)\n",
    "\t\t#except RuntimeError as e:\n",
    "\t\t\t#print(f'error at d_ij_transform: {e}')\n",
    "\t\t\t#raise\n",
    "\n",
    "\t\t# Transform the distance projection, nuclear charges and atom embeddings\n",
    "\t\td_ij_t_projection = self.d_ij_transform(edge_features)\n",
    "\t\t#print(f'dijt shape: {d_ij_t_projection.shape}') # 77, 256\n",
    "\t\ta_i_projection = self.a_i_transform(x[edge_index[0, :]])\n",
    "\t\ta_j_projection = self.a_j_transform(x[edge_index[1, :]])\n",
    "\n",
    "\t\t#print('Z shape:'z.shape) # 18, 1\n",
    "\t\t#print('Edge index:'edge_index.shape) # 2, 63\n",
    "\n",
    "\t\t#print('z.type:',z.dtype) # torch.int64\n",
    "\t\t#print('edge type:',edge_index.dtype) # torch.int64\n",
    "\n",
    "\t\t#z = z.float()\n",
    "\n",
    "\t\t#print(f\"x shape: {x.shape}\") , # 18 256\n",
    "\n",
    "\t\t#print(f\"x shape before sage1: {x.shape}\")\n",
    "\t\t#print(f\"Before GNN: mean {x.mean().item()}, std {x.std().item()}, min {x.min().item()}, max {x.max().item()}\")\n",
    "\n",
    "\t\t#z =self.sage1(x, edge_index)\n",
    "\t\t#z=F.silu(z)\n",
    "\t\t# print(f\"After SAGE1: mean {z.mean().item()}, std {z.std().item()}, min {z.min().item()}, max {z.max().item()}\")\n",
    "\n",
    "\t\t#print(f\"z shape after sage1: {z.shape}\")\n",
    "\n",
    "\t\t#z = self.sage2(z, edge_index)\n",
    "\t\t#z=F.silu(z)\n",
    "\t\t# print(f\"After SAGE2: mean {z.mean().item()}, std {z.std().item()}, min {z.min().item()}, max {z.max().item()}\")\n",
    "\n",
    "\t\t#print('z shape after 2: ', z.shape)\n",
    "\n",
    "\t\t#z = self.sage3(z, edge_index)\n",
    "\t\t#z=F.silu(z)\n",
    "\t\t# print(f\"After SAGE3: mean {z.mean().item()}, std {z.std().item()}, min {z.min().item()}, max {z.max().item()}\")\n",
    "\n",
    "\t\t#print(f\"SAGE1 output shape: {x.shape}\")\n",
    "\t\t#print(f\"SAGE2 output shape: {x.shape}\")\n",
    "\t\t#print(f\"SAGE3 output shape: {x.shape}\")\n",
    "\n",
    "\t\t#Need to specify the gnn output i.e. what it all is then put it here\n",
    "\t\t#x1 = self.sage1(z, edge_index)\n",
    "\t\t#x2 = self.sage2(x1, edge_index)  # explicitly giving required edge_index explicitly clearly explicitly explicitly explicitly\n",
    "\t\t#gnn_output = self.sage3(x2, edge_index)  # explicitly every layer explicitly clearly exactly matched exactly explicitly explicitly\n",
    "\n",
    "\t\t# ? Atomwise???\n",
    "\t\t#gnn_output = F.silu(self.edge1(x, edge_index))\n",
    "\t\t#gnn_output = F.silu(self.edge1(x, edge_index))\n",
    "\n",
    "\t\t# ? Pairwise gnn output maybe input too? added non linearity\n",
    "\t\t#gnn_output = torch.cat([x, edge_index], dim=1)\n",
    "\n",
    "\t\t#print(f\"GNN Output Shape: {gnn_output.shape}\")\n",
    "\t\t#print(f\"Edge Index Shape: {edge_index.shape}\")\n",
    "\n",
    "\t\t# Extract edge-level features by indexing, 0 = source nodes, 1 = target nodes\n",
    "\t\t#gnn_edge_features = torch.cat([gnn_output[edge_index[0]], gnn_output[edge_index[1]]], dim=1)\n",
    "\n",
    "\t\t#Sageconv handles edge_index and edge_weight, also takes z , need to put these into a parameter and pytorch will handlet this\n",
    "\n",
    "\t\t#print(f\"a_i_projection shape: {a_i_projection.shape}\")\n",
    "\t\t#print(f\"a_j_projection shape: {a_j_projection.shape}\")\n",
    "\t\t#print(f\"d_ij_t_projection shape: {d_ij_t_projection.shape}\")\n",
    "\t\t#print(f\"gnn_edge_features shape: {gnn_edge_features.shape}\")\n",
    "\n",
    "\t\t# Ensure all tensors have the same first dimension\n",
    "\t\t#min_edges = min(a_i_projection.shape[0], a_j_projection.shape[0], d_ij_t_projection.shape[0])\n",
    "\t\t#a_i_projection = a_i_projection[:min_edges]\n",
    "\t\t#a_j_projection = a_j_projection[:min_edges]\n",
    "\t\t#d_ij_t_projection = d_ij_t_projection[:min_edges]\n",
    "\t\t#gnn_edge_features = gnn_edge_features[:min_edges]\n",
    "\n",
    "\t\t#concat_gnn = torch.cat([a_i_projection, a_j_projection, d_ij_t_projection, gnn_edge_features], dim=1)\n",
    "\t\t#concat_gnn = self.projection_layer(concat_gnn)\n",
    "\t\t#concat_gnn = self.projection_layer_x(concat_gnn)  # New projection to reduce dimensions\n",
    "\n",
    "\t\t#print(a_i_projection.shape)\n",
    "\t\t#print(a_j_projection.shape)\n",
    "\t\t#print(d_ij_t_projection.shape)\n",
    "\t\t#print(gnn_edge_features.shape)\n",
    "\n",
    "\t\t# ! New code 26/03\n",
    "\t\t#concat_gnn = torch.cat([a_i_projection, a_j_projection, d_ij_t_projection, gnn_edge_features], dim=1)\n",
    "\t\t#print(f\"concat_gnn shape before projection: {concat_gnn.shape}\")\n",
    "\t\t#concat_gnn = self.concat_projection(concat_gnn)\n",
    "\t\t#concat_gnn = concat_gnn.view(-1, 384)\n",
    "\t\t#print(f\"concat_gnn shape: {concat_gnn.shape}\")\n",
    "\n",
    "\t\t# ? Did you want a linear layer here to transform after concat ? self gamma transform is now linear\n",
    "\t\t#gamma_projection = self.gamma_transform(torch.cat([a_i_projection.squeeze(), a_j_projection.squeeze(), d_ij_t_projection], dim=1))\n",
    "\n",
    "\t\tgamma_projection = self.gamma_transform(torch.cat([a_i_projection, a_j_projection, d_ij_t_projection], dim=1))\n",
    "\n",
    "\t\t#gamma_projection = self.gamma_transform(torch.cat([a_i_projection, a_j_projection, d_ij_t_projection], dim=1)) # Pairwise here, try to do this if append below is not accurate\n",
    "\n",
    "\t\t#Combine the source and target atom features then apply transformation to better learn them\n",
    "\n",
    "\t\t# Process each feature projection separately\n",
    "\t\t#gamma_i = self.gamma_transform_i(a_i_projection)\n",
    "\t\t#gamma_j = self.gamma_transform_j(a_j_projection)\n",
    "\t\t#gamma_projection = gamma_i + gamma_j  # or any other combination method\n",
    "\n",
    "\t\t# Computing Z:\n",
    "\t\td_ij_expanded = torch.repeat_interleave(edge_weight, self.num_gates, dim=0)\n",
    "\n",
    "\t\td_ij_expanded = 1 / torch.clamp(\n",
    "\t\t\ttorch.abs(d_ij_expanded.view(\n",
    "\t\t\t\t-1,\n",
    "\t\t\t\tself.t_parameters.size(0)\n",
    "\t\t\t) - self.t_parameters),\n",
    "\t\t\tmin=1e-8 # Avoid division by zero\n",
    "\t\t)\n",
    "\t\tsoftmax_d_ij_expanded = F.softmax(d_ij_expanded, dim=1)\n",
    "\n",
    "\n",
    "\t\texperts_output = [self.experts[i](gamma_projection) for i in range(self.num_gates)]\n",
    "\n",
    "\t\texperts_contributions = [e_o * e_w for e_o, e_w in zip(experts_output, softmax_d_ij_expanded.split(1, dim=1))]\n",
    "\t\t# do the sum of the experts_contributions\n",
    "\t\tedge_level_output = torch.sum(torch.stack(experts_contributions, dim=0), dim=0)\n",
    "\n",
    "\t\t# Doing aggregation over the atoms\n",
    "\t\tatom_level_output_x = scatter(edge_level_output, edge_index[0], dim=0, reduce=\"sum\") # Concat gnn_output here\n",
    "\n",
    "\t\t#Then add another MLP layer here to transfer so I can concat.\n",
    "\n",
    "\t\t# Doing the equivariant operation\n",
    "\t\tn_atoms = z.size(0)  # Number of atoms from z\n",
    "\t\tatom_level_output = torch.zeros(n_atoms, self.experts[0].out_features, dtype=self.dtype, device=z.device)\n",
    "\t\tvec = torch.zeros(n_atoms, 3, self.experts[0].out_features, dtype=self.dtype,\n",
    "\t\t                  device=z.device)  # Atom-level vector features\n",
    "\n",
    "\t\t# Aggregate edge-level scalar output to atom-level using scatter_reduce (sum)\n",
    "\t\tatom_level_output.index_add_(0, edge_index[0], edge_level_output)  # Sum edge outputs to source atoms\n",
    "\n",
    "\t\t# Aggregate edge-level vector features to atom-level using scatter_reduce (sum)\n",
    "\t\t# Map edge_vec (shape: (num_edges, 3)) to atom-level vec\n",
    "\t\t# First, expand edge_vec to match expert_out_features\n",
    "\t\tedge_vec_expanded = edge_vec.unsqueeze(-1).repeat(1, 1, self.experts[\n",
    "\t\t\t0].out_features)  # Shape: (num_edges, 3, expert_out_features)\n",
    "\t\t# Weight edge_vec_expanded by edge_level_output (broadcasting)\n",
    "\t\tweighted_edge_vec = edge_vec_expanded * edge_level_output.unsqueeze(\n",
    "\t\t\t1)  # Shape: (num_edges, 3, expert_out_features)\n",
    "\t\t# Aggregate to atom-level using scatter_reduce (sum) for source atoms\n",
    "\t\tfor dim in range(3):  # Iterate over spatial dimensions (0, 1, 2)\n",
    "\t\t\t# Extract the dim-th spatial component of weighted_edge_vec\n",
    "\t\t\tweighted_edge_vec_dim = weighted_edge_vec[:, dim, :]  # Shape: (num_edges, expert_out_features)\n",
    "\t\t\t# Aggregate to atom-level using index_add_ for source atoms\n",
    "\t\t\tvec[:, dim, :].index_add_(0, edge_index[0], weighted_edge_vec_dim)\n",
    "\n",
    "\t\treturn atom_level_output_x, vec, z, pos, batch\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\timport torch\n",
    "\timport numpy as np\n",
    "\timport random\n",
    "\timport time\n",
    "\n",
    "\n",
    "\tdef set_seed(seed: int):\n",
    "\t\ttorch.manual_seed(seed) # Ensures random number generator is deterministic on the cpu\n",
    "\t\tnp.random.seed(seed)\n",
    "\t\trandom.seed(seed)\n",
    "\t\tif torch.cuda.is_available(): # Makes sure CUDA is set with the same seed, GPU results now reproducable\n",
    "\t\t\ttorch.cuda.manual_seed(seed)\n",
    "\t\t\ttorch.cuda.manual_seed_all(seed)\n",
    "\t\ttorch.backends.cudnn.deterministic = True # GPU ops deterministic\n",
    "\t\ttorch.backends.cudnn.benchmark = False # Avoid non deterministic behaviour when input size not fixed\n",
    "\n",
    "\n",
    "\t# Set the seed\n",
    "\tset_seed(2000)\n",
    "\t# Test the model\n",
    "\tmodel = DeepSet(\n",
    "                   base_cutoff=0.0,\n",
    "                   outer_cutoff=3.0,\n",
    "                   # radial_basis=None,\n",
    "                   # use_vector_representation=True,\n",
    "                   # forces_based_on_energy=False,\n",
    "                   # close_far_split=True,\n",
    "                   # using_triplet_module=True\n",
    "\t)\n",
    "\n",
    "\n",
    "\t# Generate random input\n",
    "\tz = torch.randint(1, 100, (18, 1))\n",
    "\t# print(z.size())\n",
    "\tpos = torch.randint(0, 5, (18, 3), dtype=torch.float32)\n",
    "\tbatch = torch.zeros(100, dtype=torch.long)\n",
    "\t# box = torch.rand(3, 3)\n",
    "\tx, vec, z, pos, batch = model(z, pos, batch)"
   ],
   "id": "8a9a28c010ef69c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "INPUT_PATH = \"ani1x.h5\"\n",
    "OUTPUT_DIR = \"moleculewise_splits\"\n",
    "NUM_SPLITS = 5\n",
    "SEED = 42\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "random.seed(SEED)\n",
    "\n",
    "def load_molecules(h5file):\n",
    "    \"\"\"\n",
    "    Loads and groups all conformers by molecule.\n",
    "    Returns: dict of {mol_id: list of conformers}, each conformer is a dict\n",
    "    \"\"\"\n",
    "    mol_data = {}\n",
    "    for mol in h5file.keys():\n",
    "        z = h5file[f\"{mol}/atomic_numbers\"][:]\n",
    "        pos = h5file[f\"{mol}/coordinates\"][:]   # (N_confs, N_atoms, 3)\n",
    "        energy = h5file[f\"{mol}/energies\"][:]   # (N_confs,)\n",
    "\n",
    "        if len(pos) != len(energy):\n",
    "            continue  # skip malformed entries\n",
    "\n",
    "        conformers = []\n",
    "        for i in range(len(energy)):\n",
    "            conformers.append({\n",
    "                'z': z,\n",
    "                'pos': pos[i],\n",
    "                'y': energy[i]\n",
    "            })\n",
    "\n",
    "        mol_data[mol] = conformers\n",
    "    return mol_data\n",
    "\n",
    "def moleculewise_split(mol_data, k=5):\n",
    "    \"\"\"\n",
    "    Split molecule dictionary into k folds.\n",
    "    Returns: list of splits, each is a list of conformers.\n",
    "    \"\"\"\n",
    "    mol_ids = list(mol_data.keys())\n",
    "    random.shuffle(mol_ids)\n",
    "\n",
    "    splits = [[] for _ in range(k)]\n",
    "    for i, mol in enumerate(mol_ids):\n",
    "        split_id = i % k\n",
    "        splits[split_id].extend(mol_data[mol])  # Add all conformers of this molecule\n",
    "\n",
    "    return splits\n",
    "\n",
    "def save_split(split_data, split_id):\n",
    "    \"\"\"\n",
    "    Save a split to a .npz file in TorchMD format.\n",
    "    \"\"\"\n",
    "    npz_data = {\n",
    "        'z': [item['z'] for item in split_data],\n",
    "        'pos': [item['pos'] for item in split_data],\n",
    "        'y': [item['y'] for item in split_data],\n",
    "    }\n",
    "    npz_data = {k: np.array(v, dtype=object) for k, v in npz_data.items()}\n",
    "    out_path = os.path.join(OUTPUT_DIR, f\"split_{split_id}.npz\")\n",
    "    np.savez_compressed(out_path, **npz_data)\n",
    "    print(f\"Saved split {split_id} with {len(split_data)} conformers\")\n",
    "\n",
    "def main():\n",
    "    with h5py.File(INPUT_PATH, 'r') as h5file:\n",
    "        print(\"Loading molecules...\")\n",
    "        mol_data = load_molecules(h5file)\n",
    "\n",
    "    print(f\"Total molecules: {len(mol_data)}\")\n",
    "    splits = moleculewise_split(mol_data, NUM_SPLITS)\n",
    "\n",
    "    for i, split in enumerate(splits):\n",
    "        save_split(split, i)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "e1c067ed0fc9330f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
