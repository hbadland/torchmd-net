{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, Optional, Union, List\n",
    "import typing\n",
    "import wandb\n",
    "import rich\n",
    "from rich import pretty\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as tg\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import xavier_uniform_, zeros_\n",
    "from torch.nn import init\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, GATv2Conv\n",
    "\n",
    "from torchmdnet.models.utils import (\n",
    "\tNeighborEmbedding,\n",
    "\tCosineCutoff,\n",
    "\tOptimizedDistance,\n",
    "\trbf_class_mapping,\n",
    "\tact_class_mapping,\n",
    "\tscatter,\n",
    ")\n",
    "\n",
    "# from src import utils\n",
    "# from src.properties import properties\n",
    "\n",
    "__all__ = [\"DeepSet\"]\n",
    "\n",
    "class DeepSet(nn.Module):\n",
    "\n",
    "\tdef __init__(\n",
    "\t\t\tself,\n",
    "\t\t\tin_channels: int = 128,\n",
    "\t\t\thidden_channels: int = 256,\n",
    "\t\t\tout_channels: int = 32,\n",
    "\t\t\tnum_gates: int = 10,\n",
    "\t\t\tskip_duplicates: bool = True,\n",
    "\t\t\tbase_cutoff: float = 0.0,\n",
    "\t\t\touter_cutoff: float = 5.0,\n",
    "\t\t\tk: int = 2,\n",
    "\t\t\tmax_num_neighbors: int = 400,\n",
    "\t\t\tembedding_size: int = 256,\n",
    "\t\t\tnum_rbf: int = 50,\n",
    "\t\t\texpert_out_features: int = 128,\n",
    "\t\t\trbf_type: str = \"gauss\",\n",
    "\t\t\ttrainable_rbf: bool = False,\n",
    "\t\t\tdtype: torch.dtype = torch.float32\n",
    "\t):\n",
    "\n",
    "\t\tsuper(DeepSet, self).__init__()\n",
    "\n",
    "\t\tself.outer_cutoff = outer_cutoff\n",
    "\t\tself.base_cutoff = base_cutoff\n",
    "\t\tself.embedding_size = embedding_size\n",
    "\t\tself.dtype = dtype\n",
    "\t\tself.skip_duplicates = skip_duplicates\n",
    "\t\tself.in_channels = in_channels\n",
    "\t\tself.hidden_channels = hidden_channels\n",
    "\t\tself.out_channels = out_channels\n",
    "\t\tself.num_gates = num_gates\n",
    "\n",
    "\t\t#Atom embedding\n",
    "\t\tself.atom_embedding = nn.Linear(1, 64)\n",
    "\t\t#self.projection_layer = nn.Linear(1152, 128)\n",
    "\t\t#self.projection_layer_x = nn.Linear(128, 256)\n",
    "\t\tself.gamma_transform = nn.Linear(256, 384) # ! Had to set to 384 to work with experts\n",
    "\t\t#self.gnn = nn.Sequential(SAGEConv(in_channels, hidden_channels), nn.SiLU(), SAGEConv(hidden_channels, hidden_channels))\n",
    "\n",
    "\t\tself.distance = OptimizedDistance(\n",
    "\t\t    base_cutoff,\n",
    "\t\t    outer_cutoff,\n",
    "\t\t    max_num_pairs=max_num_neighbors,\n",
    "\t\t    return_vecs=True,\n",
    "\t\t    loop=True,\n",
    "\t\t    box=None,\n",
    "\t\t    long_edge_index=True,\n",
    "\t\t    check_errors=True, # Set False if there are more than 10k neighbors and it throw an error. Check this thread: https://github.com/torchmd/torchmd-net/issues/203\n",
    "\t\t)\n",
    "\n",
    "\t\tself.distance_expansion = rbf_class_mapping[rbf_type](\n",
    "\t\t\tbase_cutoff, outer_cutoff, num_rbf, trainable_rbf\n",
    "\t\t)\n",
    "\t\t# Creates connected linear layer\n",
    "\t\tself.distance_proj = nn.Linear(num_rbf, embedding_size, dtype=dtype) #transforms size num_rbf into embedding_size\n",
    "\t\tself.cutoff = CosineCutoff(base_cutoff, outer_cutoff) #Restrict interactions beyond a certain distance\n",
    "\t\tself.embedding = nn.Embedding(100, 256, dtype=dtype) #Embedding layer maps ints\n",
    "\n",
    "\t\tself.neighbor_embedding = NeighborEmbedding(embedding_size, 20, base_cutoff, outer_cutoff, 100, dtype)\n",
    "\t\t#Part of a message passing NN/GNN\n",
    "\t\texpanded_feature_dim = embedding_size + 4\n",
    "\t\tself.d_ij_transform = nn.Linear(132, 256, dtype=dtype) #Refine how inter atomic distances contribute\n",
    "\t\tself.a_i_transform = nn.Linear(256, 256, dtype=dtype) #Project atom features into a common space before interactions\n",
    "\t\tself.a_j_transform = nn.Linear(256, 256, dtype=dtype) #When node i receives messages from j (neighbors) those messages are transformed properly.\n",
    "\n",
    "\t\t# ? New code 26/03\n",
    "\t\tself.pairwise_transform = nn.Linear(embedding_size + 3, embedding_size, dtype=dtype)\n",
    "\n",
    "\t\tself.sage1 = SAGEConv(256, hidden_channels, aggr='max')\n",
    "\t\t# self.norm1 = torch.nn.LayerNorm(256) Batch norm NOT for MD\n",
    "\t\t#self.gat1 = GATConv(256, hidden_channels, aggr='mean')\n",
    "\n",
    "\t\t# self.sage2 = tg.nn.SAGEConv(256, 256, aggr='sum')\n",
    "\n",
    "\t\t# self.sage3 = tg.nn.SAGEConv(256, 256, aggr='max')\n",
    "\n",
    "\t\t# self.lin = torch.nn.Linear(hidden_channels, out_channels, dtype=dtype)\n",
    "\t\t# self.lin = torch.nn.Linear(256, 64)\n",
    "\n",
    "\t\tself.concat_projection = nn.Linear(5 * hidden_channels, 256)\n",
    "\n",
    "\t\t#nn.init.xavier_uniform_(self.embedding.weight)\n",
    "\n",
    "\t\t#Gated message passing system\n",
    "\t\t#self.gamma_transform = nn.Linear(3 * embedding_size, embedding_size, dtype=dtype) # 3 suggests processing diff inputs i.e. central, neighbour and edge\n",
    "\t\t# Shape: (num_features, num_gates)\n",
    "\t\tself.W_g = nn.Parameter(torch.randn(embedding_size, num_gates) * 0.01)  # Small random initialization // gating mechanism controls info flow and selects important messages\n",
    "\n",
    "\t\t# Noise weight matrix W_noise\n",
    "\t\t# Shape: (num_features, num_gates)\n",
    "\t\tself.W_noise = nn.Parameter(torch.randn(embedding_size, num_gates) * 0.01)  # Small random initialization\n",
    "\n",
    "\t\t# Distance Learnable Parameters (Steven's method)\n",
    "\t\tself.W_distance = nn.Parameter(torch.randn(embedding_size, num_gates) * 0.01)\n",
    "\n",
    "\t\tself.t_parameters = nn.Parameter(torch.randn(num_gates) * 0.01)\n",
    "\n",
    "\t\t# Hyperparameter k for top-k selection\n",
    "\t\t# self.k = k\n",
    "\t\tself.num_gates = num_gates\n",
    "\n",
    "\t\tself.experts = nn.ModuleList([ #List of independent layers with each acting as an expert\n",
    "\t\t\tnn.Linear(384, expert_out_features, dtype=dtype)\n",
    "\t\t\tfor _ in range(num_gates)  # One expert per gate (to handle all possible gates)\n",
    "\t\t])\n",
    "\t\t#Gating mechanism chooses which experts contribute to output.\n",
    "\n",
    "\tdef reset_parameters(self):\n",
    "\t\t...\n",
    "\n",
    "\t#Numpy style docstring\n",
    "\tdef forward(self,\n",
    "\t            z: torch.Tensor, # Type hints, here for readability and clarity\n",
    "\t            pos: torch.Tensor,\n",
    "\t            batch: torch.Tensor, #based on batch can say how many indexes belong to one molecule, print nd compare with z + pos\n",
    "\t            box: Optional[torch.Tensor] = None,\n",
    "\t            q: Optional[torch.Tensor] = None,\n",
    "\t            s: Optional[torch.Tensor] = None) -> typing.Tuple[\n",
    "\t\ttorch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "\t\t\"\"\"\n",
    "\t\t#Google style doc string\n",
    "\t\tArgs:\n",
    "\t\t\tz:                                  # Size is like (n_atoms, 1)\n",
    "\t\t\tpos:                                # Size is like (n_atoms, 3)\n",
    "\t\t\tbatch:  \t\t\t\t\t\t    # Size is like (n_atoms, 1)\n",
    "\t\t\tbox:            \t\t            # Size is like (3, 3)\n",
    "\t\t\tq:                                  # Size is like (n_atoms, 1)\n",
    "\t\t\ts:      \t\t\t\t\t        # Size is like (n_atoms, 1)\n",
    "\n",
    "\t\tReturns:\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\t#Beginning the forward pass, ! had to squeeze to fix dimension errors\n",
    "\t\tz = z.view(-1, 1)\n",
    "\t\tx = self.embedding(z.long()).squeeze(1)\n",
    "\t\t#x = nn.Dropout(0.1)(x)\n",
    "\t\t#print(\"z shape before SAGEConv:\", z.shape)\n",
    "\t\t#print(f\"x shape before SAGEConv: {x.shape}\") # should be numnodes, 64\n",
    "\n",
    "\n",
    "\t\tedge_index, edge_weight, edge_vec = self.distance(pos, batch, box) #Finds pairs of atoms close and returns which atoms are connected, their distance and direction\n",
    "\t\t#Edge weight distance, take as x\n",
    "\n",
    "\t\t#num_nodes = z.shape[0]\n",
    "\t\t#if edge_index.max() >= num_nodes:\n",
    "\t\t\t#print(f'Edge index contains out of bounds value')\n",
    "\t\t\t#edge_index = edge_index.clamp(0, num_nodes - 1)\n",
    "\n",
    "\t\t#edge_index = edge_index.long()\n",
    "\n",
    "\t\tedge_attr = self.distance_expansion(edge_weight) #Converts raw distances between atoms into a better format, NN struggle with raw values\n",
    "\t\t# ! New code 26/03\n",
    "\t\tedge_proj = self.distance_proj(edge_attr)\n",
    "\n",
    "\t\tedge_vec = edge_vec / (torch.norm(edge_vec, dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "\t\t#print(\"edge_weight shape (mask):\", (edge_weight != 0).shape) # 142\n",
    "\t\t#print(\"edge_attr shape:\", edge_attr.shape) # 142, 50\n",
    "\n",
    "\t\t#edge_index = edge_index[:, edge_weight != 0]\n",
    "\t\t#edge_weight = edge_weight[edge_weight != 0] # * Prevent self loops (No distance between same an atom so it should be 0)\n",
    "\t\t#edge_vec = edge_vec[edge_vec != 0]\n",
    "\n",
    "\t\t#print(\"After filtering zeros:\")\n",
    "\t\t#print(\"edge_weight.shape:\", edge_weight.shape)\n",
    "\t\t#print(\"edge_attr.shape:\", edge_attr.shape)\n",
    "\n",
    "\t\tmask = edge_index[0] != edge_index[1] #Mask used to handle anomalous data points , filters out self loops (source and target)\n",
    "\t\tif not mask.all(): #Checks for any false values in the mask, if so then following code is executed\n",
    "\t\t\tedge_index = edge_index[:, mask]\n",
    "\t\t\tedge_weight = edge_weight[mask]\n",
    "\t\t\tedge_attr = edge_attr[mask]\n",
    "\t\t\tedge_vec = edge_vec[mask]\n",
    "\t\t\tedge_proj = edge_proj[mask]# Mask edge_vec as well\n",
    "\n",
    "\t\t#print(f\"Mask shape:\", mask.shape)\n",
    "\n",
    "\t\tif self.skip_duplicates: # this remove repeated edges in calculation (it means upper triangle matrix)\n",
    "\t\t\tedge_index = edge_index[:, ::2] #Slicing, selects every second edge so skips over dupes\n",
    "\t\t\tedge_weight = edge_weight[::2] #Slice with 2 to skip duplicate edges and keep only one direction\n",
    "\t\t\tedge_attr = edge_attr[::2]\n",
    "\t\t\tedge_vec = edge_vec[::2]\n",
    "\t\t\tedge_proj = edge_proj[::2]\n",
    "\n",
    "\t\t#edge_index = edge_index.float()\n",
    "\n",
    "\t\t#print(f\"Edge index shape: {edge_index.shape}\") # [2, 62]\n",
    "\t\t#print(f\"Max index in edge_index: {edge_index.max().item()}\") # 17 , none out of bounds\n",
    "\t\t#print(f\"Number of nodes (atoms): {z.shape[0]}\")  # 18\n",
    "\n",
    "\t\t#print(f\"Edge weight sample: {edge_weight[:5]}\")\n",
    "\t\t#print(f\"Edge vec sample: {edge_vec[:5]}\") Aligned properly\n",
    "\n",
    "\t\t#print(f\"Min edge index: {edge_index.min().item()}\") # 1\n",
    "\t\t#print(f\"Max edge index: {edge_index.max().item()}\") # 17\n",
    "\n",
    "\t\t#print(f\"Node feature shape: {x.shape}\")  # ([18, 1, 256)]) but needs to be 2D so is causing an issue\n",
    "\n",
    "\t\t# Added for project\n",
    "\t\t#edge_weight_sq = edge_weight ** 2\n",
    "\t\tedge_weight_cube = edge_weight ** 3\n",
    "\t\t#edge_weight_tet = edge_weight ** 4\n",
    "\t\tedge_weight_sqrt = torch.sqrt(edge_weight)\n",
    "\t\t#edge_weight_log = torch.log(edge_weight)\n",
    "\n",
    "\t\tedge_weight: torch.Tensor  # Type hint, edge_weight is expected to be a tensor\n",
    "\n",
    "\t\t# Normalize edge_vec for masked edges (similar to TorchMD_ET)\n",
    "\t\tedge_vec = edge_vec / torch.clamp(torch.norm(edge_vec, dim=1, keepdim=True), min=1e-8)\n",
    "\t\t#edge_vec.squeeze(3)\n",
    "\n",
    "\t\t#print(f\"Edge weight shape: {edge_weight.shape}\")\n",
    "\t\t#print(f\"Edge vec shape: {edge_vec.shape}\")\n",
    "\n",
    "\t\t# Compute the cutoff and distance projection\n",
    "\t\tC = self.cutoff(edge_weight) # Applies cutoff function to edge weight tensor, limits interactions to certain threshold.\n",
    "\t\td_ij_projection = edge_proj * C.view(-1, 1) # Applies cutoff values to projections. If edge is zero then it is reflected here.\n",
    "\n",
    "\t\t#print(f\"edge_proj shape: {edge_proj.shape}\") # 168, 256 clearly the issue\n",
    "\t\t#print(f\"edge_weight_cube shape: {edge_weight_cube.shape}\") # 75\n",
    "\t\t#print(f\"edge_weight_sqrt shape: {edge_weight_sqrt.shape}\") # 75\n",
    "\t\t#print(f\"edge_weight shape: {edge_weight.shape}\") # 75\n",
    "\t\t#print(f\"edge_vec shape: {edge_vec.shape}\") # 75,3 thus should flatten\n",
    "\n",
    "\t\tedge_vec_flat = edge_vec.mean(dim=1)\n",
    "\n",
    "\n",
    "\t\t# !Concat new weights to the projection, since dim = 1 need to ensure concat along a column ??\n",
    "\t\tedge_features = torch.cat(\n",
    "[\n",
    "\t\t\td_ij_projection,\n",
    "\t\t\t #edge_weight_sq.view(-1,1),\n",
    "\t\t\t edge_weight_cube.view(-1,1),\n",
    "\t\t\t #edge_weight_tet.view(-1,1),\n",
    "\t\t\t edge_weight_sqrt.view(-1,1),\n",
    "\t\t\t #edge_weight_log.view(-1,1),\n",
    "\t\t\t edge_weight.view(-1,1),\n",
    "\t\t\tedge_vec_flat.view(-1,1)\n",
    "\t\t],\tdim=1\n",
    "\t\t)\n",
    "\n",
    "\t\t#print(f\"edge_proj shape : {edge_proj.shape}\")  #\n",
    "\t\t#print(f\"edge_weight_cube : {edge_weight_cube.shape}\")  # 75\n",
    "\t\t#print(f\"edge_weight_sqrt shape : {edge_weight_sqrt.shape}\")  # 75\n",
    "\t\t#print(f\"edge_weight shape : {edge_weight.shape}\")  # 75\n",
    "\t\t#print(f\"edge_vec shape : {edge_vec_flat.shape}\")\n",
    "\n",
    "\t\t# ? I have to transform 260 input to 259 output linearly, here accuracy will be lost\n",
    "\n",
    "\t\t#print(f\"x shape: {x.shape}\")  # [18, 256]\n",
    "\t\t#print(f'edge_features.shape BEFORE Linear: {edge_features.shape}')  # [77, 260]\n",
    "\t\t#assert edge_features.shape == (77, 260), f\"Unexpected shape: {edge_features.shape}\"\n",
    "\n",
    "\t\t#print(\"Edge features shape:\", edge_features.shape)  # (77, 260)\n",
    "\t\t#print(\"Expected input dim:\", self.d_ij_transform.in_features)  #  260\n",
    "\t\t#print(\"Expected output dim:\", self.d_ij_transform.out_features)  # 256\n",
    "\n",
    "\t\t#try:\n",
    "\t\t\t#d_ij_t_projection = self.d_ij_transform(edge_features)\n",
    "\t\t#except RuntimeError as e:\n",
    "\t\t\t#print(f'error at d_ij_transform: {e}')\n",
    "\t\t\t#raise\n",
    "\n",
    "\t\t# Transform the distance projection, nuclear charges and atom embeddings\n",
    "\t\td_ij_t_projection = self.d_ij_transform(edge_features)\n",
    "\t\t# print(f'dijt shape: {d_ij_t_projection.shape}') # 77, 256\n",
    "\t\ta_i_projection = self.a_i_transform(x[edge_index[0, :]])\n",
    "\t\ta_j_projection = self.a_j_transform(x[edge_index[1, :]])\n",
    "\n",
    "\t\t#print('Z shape:'z.shape) # 18, 1\n",
    "\t\t#print('Edge index:'edge_index.shape) # 2, 63\n",
    "\n",
    "\t\t#print('z.type:',z.dtype) # torch.int64\n",
    "\t\t#print('edge type:',edge_index.dtype) # torch.int64\n",
    "\n",
    "\t\tz = z.float()\n",
    "\n",
    "\t\t#print(f\"x shape before linear: {x.shape}\") , # 18 256\n",
    "\n",
    "\t\t#print(f\"x shape before sage1: {x.shape}\")\n",
    "\t\t#print(f\"Before GNN: mean {x.mean().item()}, std {x.std().item()}, min {x.min().item()}, max {x.max().item()}\")\n",
    "\n",
    "\t\t#z =self.sage1(x, edge_index)\n",
    "\t\t#z=F.silu(z)\n",
    "\t\t# print(f\"After SAGE1: mean {z.mean().item()}, std {z.std().item()}, min {z.min().item()}, max {z.max().item()}\")\n",
    "\n",
    "\t\t#print(f\"z shape after sage1: {z.shape}\")\n",
    "\n",
    "\t\t#z = self.sage2(z, edge_index)\n",
    "\t\t#z=F.silu(z)\n",
    "\t\t# print(f\"After SAGE2: mean {z.mean().item()}, std {z.std().item()}, min {z.min().item()}, max {z.max().item()}\")\n",
    "\n",
    "\t\t#print('z shape after 2: ', z.shape)\n",
    "\n",
    "\t\t#z = self.sage3(z, edge_index)\n",
    "\t\t#z=F.silu(z)\n",
    "\t\t# print(f\"After SAGE3: mean {z.mean().item()}, std {z.std().item()}, min {z.min().item()}, max {z.max().item()}\")\n",
    "\n",
    "\t\t#print(f\"SAGE1 output shape: {x.shape}\")\n",
    "\t\t#print(f\"SAGE2 output shape: {x.shape}\")\n",
    "\t\t#print(f\"SAGE3 output shape: {x.shape}\")\n",
    "\n",
    "\t\t#Need to specify the gnn output i.e. what it all is then put it here\n",
    "\t\t#x1 = self.sage1(z, edge_index)\n",
    "\t\t#x2 = self.sage2(x1, edge_index)  # explicitly giving required edge_index explicitly clearly explicitly explicitly explicitly\n",
    "\t\t#gnn_output = self.sage3(x2, edge_index)  # explicitly every layer explicitly clearly exactly matched exactly explicitly explicitly\n",
    "\n",
    "\t\t# ? Atomwise\n",
    "\t\t#gnn_output = self.sage1(d_ij_t_projection, edge_index)\n",
    "\t\t#gnn_output = self.sage2(gnn_output, edge_index)\n",
    "\t\t#gnn_output = self.sage3(gnn_output, edge_index)\n",
    "\n",
    "\t\t# ? Pairwise gnn output\n",
    "\t\tgnn_output = self.sage1(x, edge_index)\n",
    "\n",
    "\n",
    "\t\t# Extract edge-level features by indexing, 0 = source nodes, 1 = target nodes\n",
    "\t\tgnn_edge_features = torch.cat([gnn_output[edge_index[0]], gnn_output[edge_index[1]]], dim=1)\n",
    "\n",
    "\t\t#Sageconv handles edge_index and edge_weight, also takes z , need to put these into a parameter and pytorch will handlet this\n",
    "\n",
    "\t\t#print(f\"a_i_projection shape: {a_i_projection.shape}\")\n",
    "\t\t#print(f\"a_j_projection shape: {a_j_projection.shape}\")\n",
    "\t\t#print(f\"d_ij_t_projection shape: {d_ij_t_projection.shape}\")\n",
    "\t\t#print(f\"gnn_edge_features shape: {gnn_edge_features.shape}\")\n",
    "\n",
    "\t\t# Ensure all tensors have the same first dimension\n",
    "\t\t#min_edges = min(a_i_projection.shape[0], a_j_projection.shape[0], d_ij_t_projection.shape[0])\n",
    "\t\t#a_i_projection = a_i_projection[:min_edges]\n",
    "\t\t#a_j_projection = a_j_projection[:min_edges]\n",
    "\t\t#d_ij_t_projection = d_ij_t_projection[:min_edges]\n",
    "\t\t#gnn_edge_features = gnn_edge_features[:min_edges]\n",
    "\n",
    "\t\t#concat_gnn = torch.cat([a_i_projection, a_j_projection, d_ij_t_projection, gnn_edge_features], dim=1)\n",
    "\t\t#concat_gnn = self.projection_layer(concat_gnn)\n",
    "\t\t#concat_gnn = self.projection_layer_x(concat_gnn)  # New projection to reduce dimensions\n",
    "\n",
    "\t\tprint(a_i_projection.shape)\n",
    "\t\tprint(a_j_projection.shape)\n",
    "\t\tprint(d_ij_t_projection.shape)\n",
    "\t\tprint(gnn_edge_features.shape)\n",
    "\n",
    "\t\t# ! New code 26/03\n",
    "\t\tconcat_gnn = torch.cat([a_i_projection, a_j_projection, d_ij_t_projection, gnn_edge_features], dim=1)\n",
    "\t\t#print(f\"concat_gnn shape before projection: {concat_gnn.shape}\")\n",
    "\t\tconcat_gnn = self.concat_projection(concat_gnn)\n",
    "\t\t#concat_gnn = concat_gnn.view(-1, 384)\n",
    "\t\t#print(f\"concat_gnn shape: {concat_gnn.shape}\")\n",
    "\n",
    "\t\t# ? Did you want a linear layer here to transform after concat ? self gamma transform is now linear\n",
    "\t\tgamma_projection = self.gamma_transform(concat_gnn)\n",
    "\n",
    "\t\t#gamma_projection = self.gamma_transform(torch.cat([a_i_projection, a_j_projection, d_ij_t_projection, gnn_edge_features], dim=1))\n",
    "\n",
    "\t\t#gamma_projection = self.gamma_transform(torch.cat([a_i_projection, a_j_projection, d_ij_t_projection], dim=1)) # Pairwise here, try to do this if append below is not accurate\n",
    "\n",
    "\t\t#Combine the source and target atom features then apply transformation to better learn them\n",
    "\n",
    "\t\t# Process each feature projection separately\n",
    "\t\t#gamma_i = self.gamma_transform_i(a_i_projection)\n",
    "\t\t#gamma_j = self.gamma_transform_j(a_j_projection)\n",
    "\t\t#gamma_projection = gamma_i + gamma_j  # or any other combination method\n",
    "\n",
    "\t\t# Computing Z:\n",
    "\t\td_ij_expanded = torch.repeat_interleave(edge_weight, self.num_gates, dim=0)\n",
    "\n",
    "\t\td_ij_expanded = 1 / torch.clamp(\n",
    "\t\t\ttorch.abs(d_ij_expanded.view(\n",
    "\t\t\t\t-1,\n",
    "\t\t\t\tself.t_parameters.size(0)\n",
    "\t\t\t) - self.t_parameters),\n",
    "\t\t\tmin=1e-8 # Avoid division by zero\n",
    "\t\t)\n",
    "\t\tsoftmax_d_ij_expanded = F.softmax(d_ij_expanded, dim=1)\n",
    "\n",
    "\n",
    "\t\texperts_output = [self.experts[i](gamma_projection) for i in range(self.num_gates)]\n",
    "\n",
    "\t\texperts_contributions = [e_o * e_w for e_o, e_w in zip(experts_output, softmax_d_ij_expanded.split(1, dim=1))]\n",
    "\t\t# do the sum of the experts_contributions\n",
    "\t\tedge_level_output = torch.sum(torch.stack(experts_contributions, dim=0), dim=0)\n",
    "\n",
    "\t\t# Doing aggregation over the atoms\n",
    "\t\tatom_level_output_x = scatter(edge_level_output, edge_index[0], dim=0, reduce=\"sum\") # Concat gnn_output here\n",
    "\n",
    "\t\t#Then add another MLP layer here to transfer so I can concat.\n",
    "\n",
    "\t\t# Doing the equivariant operation\n",
    "\t\tn_atoms = z.size(0)  # Number of atoms from z\n",
    "\t\tatom_level_output = torch.zeros(n_atoms, self.experts[0].out_features, dtype=self.dtype, device=z.device)\n",
    "\t\tvec = torch.zeros(n_atoms, 3, self.experts[0].out_features, dtype=self.dtype,\n",
    "\t\t                  device=z.device)  # Atom-level vector features\n",
    "\n",
    "\t\t# Aggregate edge-level scalar output to atom-level using scatter_reduce (sum)\n",
    "\t\tatom_level_output.index_add_(0, edge_index[0], edge_level_output)  # Sum edge outputs to source atoms\n",
    "\n",
    "\t\t# Aggregate edge-level vector features to atom-level using scatter_reduce (sum)\n",
    "\t\t# Map edge_vec (shape: (num_edges, 3)) to atom-level vec\n",
    "\t\t# First, expand edge_vec to match expert_out_features\n",
    "\t\tedge_vec_expanded = edge_vec.unsqueeze(-1).repeat(1, 1, self.experts[\n",
    "\t\t\t0].out_features)  # Shape: (num_edges, 3, expert_out_features)\n",
    "\t\t# Weight edge_vec_expanded by edge_level_output (broadcasting)\n",
    "\t\tweighted_edge_vec = edge_vec_expanded * edge_level_output.unsqueeze(\n",
    "\t\t\t1)  # Shape: (num_edges, 3, expert_out_features)\n",
    "\t\t# Aggregate to atom-level using scatter_reduce (sum) for source atoms\n",
    "\t\tfor dim in range(3):  # Iterate over spatial dimensions (0, 1, 2)\n",
    "\t\t\t# Extract the dim-th spatial component of weighted_edge_vec\n",
    "\t\t\tweighted_edge_vec_dim = weighted_edge_vec[:, dim, :]  # Shape: (num_edges, expert_out_features)\n",
    "\t\t\t# Aggregate to atom-level using index_add_ for source atoms\n",
    "\t\t\tvec[:, dim, :].index_add_(0, edge_index[0], weighted_edge_vec_dim)\n",
    "\n",
    "\t\treturn atom_level_output_x, vec, z, pos, batch\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\timport torch\n",
    "\timport numpy as np\n",
    "\timport random\n",
    "\timport time\n",
    "\n",
    "\n",
    "\tdef set_seed(seed: int):\n",
    "\t\ttorch.manual_seed(seed) # Ensures random number generator is deterministic on the cpu\n",
    "\t\tnp.random.seed(seed)\n",
    "\t\trandom.seed(seed)\n",
    "\t\tif torch.cuda.is_available(): # Makes sure CUDA is set with the same seed, GPU results now reproducable\n",
    "\t\t\ttorch.cuda.manual_seed(seed)\n",
    "\t\t\ttorch.cuda.manual_seed_all(seed)\n",
    "\t\ttorch.backends.cudnn.deterministic = True # GPU ops deterministic\n",
    "\t\ttorch.backends.cudnn.benchmark = False # Avoid non deterministic behaviour when input size not fixed\n",
    "\n",
    "\n",
    "\t# Set the seed\n",
    "\tset_seed(2000)\n",
    "\t# Test the model\n",
    "\tmodel = DeepSet(\n",
    "                   base_cutoff=0.0,\n",
    "                   outer_cutoff=3.0,\n",
    "                   # radial_basis=None,\n",
    "                   # use_vector_representation=True,\n",
    "                   # forces_based_on_energy=False,\n",
    "                   # close_far_split=True,\n",
    "                   # using_triplet_module=True\n",
    "\t)\n",
    "\n",
    "\n",
    "\t# Generate random input\n",
    "\tz = torch.randint(1, 100, (18, 1))\n",
    "\t# print(z.size())\n",
    "\tpos = torch.randint(0, 5, (18, 3), dtype=torch.float32)\n",
    "\tbatch = torch.zeros(100, dtype=torch.long)\n",
    "\t# box = torch.rand(3, 3)\n",
    "\tx, vec, z, pos, batch = model(z, pos, batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
